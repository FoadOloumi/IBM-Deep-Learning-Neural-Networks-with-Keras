{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea86b895-2a85-4ee2-a83e-2c128955351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  \n",
       "0          0.862735       -1.217079  \n",
       "1          1.055651       -1.217079  \n",
       "2         -0.526262       -2.239829  \n",
       "3         -0.526262       -2.239829  \n",
       "4          0.070492        0.647569  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###PART C###\n",
    "\n",
    "#Importing general libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loading the concrete data from a downloaded file\n",
    "\n",
    "concrete_data_raw = pd.read_csv('concrete_data.csv')\n",
    "concrete_data_raw.head()\n",
    "concrete_data_raw.shape\n",
    "\n",
    "#Checking and cleanign the dataset\n",
    "\n",
    "concrete_data_raw.describe()\n",
    "concrete_data_raw.isnull().sum()\n",
    "\n",
    "#Age is not one of the predictors as per the assignment instructions, so it is deleted from the dataset.\n",
    "\n",
    "concrete_data = concrete_data_raw.drop('Age', axis = 1)\n",
    "\n",
    "#Separating predictors and target\n",
    "\n",
    "concrete_data_columns = concrete_data.columns \n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # All columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "\n",
    "#Normalizing data \n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "n_cols = predictors_norm.shape[1]\n",
    "predictors_norm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847cf23f-6ec4-420c-b9c7-7449b9fc9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definind the neural network/model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape = (n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97ca149-c3bf-4adf-b6fa-f9220f0ba22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 7) (721,)\n",
      "(309, 7) (309,) (309, 1)\n",
      "(50,)\n",
      "[506.46075852485995, 272.97270257488896, 355.85952551740195, 385.99926656915943, 353.81382241985284, 430.59888387082754, 528.2912976073734, 338.4577425323449, 253.9609010667547, 331.3108952754798, 326.47534074402785, 281.54003336286473, 318.67727371333365, 413.20543467597076, 372.3232208877368, 461.9646321788312, 338.5053035259378, 372.8546001650727, 522.7204011698879, 545.144769874707, 350.47625784882547, 340.0693447497731, 309.22120084140926, 427.9436640080619, 296.391725031313, 258.7692401397005, 483.7697265172345, 349.79195385022183, 281.4836704518158, 394.1637457388579, 330.63580340565034, 352.92590997086864, 220.92835856561092, 574.7211790213328, 235.35991807045679, 373.9247497752037, 465.25368606538046, 270.70668293481475, 278.2784664458693, 586.6643008225777, 482.80496129516644, 426.0697201310687, 282.1484917217831, 252.58145677331527, 354.29815331499384, 323.79685019983657, 269.877573922818, 326.27603891092645, 394.6160876941615, 416.19519267769414]\n",
      "\n",
      "The Mean of the mean squared errors is: 368.4256\n",
      "\n",
      "The Standard Deviation of the mean squared errors is: 90.7441\n"
     ]
    }
   ],
   "source": [
    "#Training the model, performing prediction and creating the list of MSEs for Part B\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Creating an empty list to store MSEs\n",
    "MSE_B = []\n",
    "\n",
    "#Performing a loop 50 times to train, test and evaluate the model, and update the MSEs\n",
    "for counter in range(50):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3) #Splitting the dataset as per instructions.\n",
    "    model_B = regression_model()\n",
    "    model_B.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 50, verbose = 0) #Training the model as per instructions.\n",
    "    \n",
    "    y_pred = model_B.predict(X_test) #Using the model to predict the test set\n",
    "    MSE_B.append(mean_squared_error(y_test, y_pred)) #Updating mean squared error list with the new value\n",
    "    \n",
    "    counter += 1 \n",
    "\n",
    "print(X_train.shape, y_train.shape) #Confirming the successful data splitting operation\n",
    "print(X_test.shape, y_test.shape, y_pred.shape) #Confirming the successful data splitting operation\n",
    "print(np.shape(MSE_B)) #Confirming the number of MSEs collected \n",
    "print(MSE_B)\n",
    "\n",
    "print(\"\\nThe Mean of the mean squared errors is: %.4f\" % np.mean(MSE_B)) #Outputting the mean of MSEs \n",
    "print(\"\\nThe Standard Deviation of the mean squared errors is: %.4f\" % np.std(MSE_B)) #Outputting the mean of MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841e7115-a9dd-4e81-abcc-ae601b98e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 7) (721,)\n",
      "(309, 7) (309,) (309, 1)\n",
      "(50,)\n",
      "[182.8192455969857, 194.8156436681752, 231.68224614614078, 198.5538257174044, 180.260235022132, 193.62835910185794, 167.06412712026838, 204.95329507679142, 187.34318948262379, 190.50604716010602, 188.84359691139053, 172.2038529530189, 195.81969405640496, 187.0716633731644, 191.02627604115744, 182.0719554865546, 196.19425102317663, 181.20936485367105, 182.27726384282997, 176.20173369908926, 184.8292896133672, 211.85015149025745, 195.47604412636846, 181.6420154471188, 181.11562531215236, 197.2049432483077, 194.2575121128852, 182.19674295776576, 204.2022455956072, 202.42300067185957, 203.742503102854, 187.50685136662975, 199.69157669504662, 208.07719218613073, 188.2320800704751, 180.2423777383003, 188.59207520252346, 182.00990604315132, 185.5889193859694, 179.8300172442967, 192.62194958243475, 186.48533970835368, 203.23218530778325, 189.3155495476914, 193.73527618171647, 217.98044927029372, 189.66115172765979, 192.0217483475203, 189.37852819920406, 181.7613074906277]\n",
      "\n",
      "The Mean of the mean squared errors is: 191.1890\n",
      "\n",
      "The Standard Deviation of the mean squared errors is: 11.4948\n",
      "\n",
      "Increasing the number of epochs has decreased the Mean of the mean squared errors.\n",
      "\n",
      "Increasing the number of epochs has decreased the Standard Deviation of the mean squared errors.\n"
     ]
    }
   ],
   "source": [
    "#Training the model, performing prediction and creating the list of MSEs for Part C\n",
    "\n",
    "#Creating an empty list to store MSEs\n",
    "MSE_C = []\n",
    "\n",
    "#Performing a loop 50 times to train, test and evaluate the model, and update the MSEs\n",
    "for counter in range(50):\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3) #Not splitting the dataset, using the same split as in Part B.\n",
    "    model_C = regression_model()\n",
    "    model_C.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, verbose = 0) #Training the model as per instructions.\n",
    "    \n",
    "    y_pred = model_C.predict(X_test) #Using the model to predict the test set\n",
    "    MSE_C.append(mean_squared_error(y_test, y_pred)) #Updating mean squared error list with the new value\n",
    "    \n",
    "    counter += 1 \n",
    "\n",
    "print(X_train.shape, y_train.shape) #Confirming the successful data splitting operation\n",
    "print(X_test.shape, y_test.shape, y_pred.shape) #Confirming the successful data splitting operation\n",
    "print(np.shape(MSE_C)) #Confirming the number of MSEs collected \n",
    "print(MSE_C)\n",
    "\n",
    "print(\"\\nThe Mean of the mean squared errors is: %.4f\" % np.mean(MSE_C)) #Outputting the mean of MSEs \n",
    "print(\"\\nThe Standard Deviation of the mean squared errors is: %.4f\" % np.std(MSE_C)) #Outputting the mean of MSEs\n",
    "\n",
    "if np.mean(MSE_C) > np.mean(MSE_B):\n",
    "    print(\"\\nIncreasing the number of epochs has increased the Mean of the mean squared errors.\")\n",
    "elif np.mean(MSE_C) == np.mean(MSE_B):\n",
    "    print(\"\\nIncreasing the number of epochs has had no effect on the Mean of the mean squared errors.\")\n",
    "else: \n",
    "    print(\"\\nIncreasing the number of epochs has decreased the Mean of the mean squared errors.\")\n",
    "    \n",
    "if np.std(MSE_C) > np.std(MSE_B):\n",
    "    print(\"\\nIncreasing the number of epochs has increased the Standard Deviation of the mean squared errors.\")\n",
    "elif np.std(MSE_C) == np.std(MSE_B):\n",
    "    print(\"\\nIncreasing the number of epochs has had no effect on the Standard Deviation of the mean squared errors.\")\n",
    "else: \n",
    "    print(\"\\nIncreasing the number of epochs has decreased the Standard Deviation of the mean squared errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e81f6-5b47-4cb5-a709-1fa5f90d8ca3",
   "metadata": {},
   "source": [
    "Discussion: \n",
    "    For this part since the intent is to compare and test the change in epoch numbers, the dataset has not been split for Part C and the same dataset\n",
    "    as in Part B has been used in order to keep the datasets consistent. Increasing the epoch number has significantly decreased the mean and STD of\n",
    "    MSEs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
